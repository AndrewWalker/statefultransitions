<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math on Stateful Transitions</title>
    <link>http://andrewwalker.github.io/statefultransitions/categories/math/</link>
    <description>Recent content in Math on Stateful Transitions</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jun 2015 21:23:37 +1000</lastBuildDate>
    <atom:link href="http://andrewwalker.github.io/statefultransitions/categories/math/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Snakes and Ladders</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/snakes-and-ladders/</link>
      <pubDate>Tue, 02 Jun 2015 21:23:37 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/snakes-and-ladders/</guid>
      <description>&lt;p&gt;One of the simplest non-trivial examples of something interesting to do with
Markov chains (that&amp;rsquo;s pretty easy to visualise and understand) is working out
how many moves (on average) it takes to complete a game of snakes and ladders?
This selection of an example is somewhat intentional because it&amp;rsquo;s the same
example as the wikipedia entry for &lt;a href=&#34;http://en.wikipedia.org/wiki/Absorbing_Markov_chain&#34;&gt;absorbing Markov
chains&lt;/a&gt;, and because it&amp;rsquo;s
just hard enough to actually justify solving the problem properly.&lt;/p&gt;

&lt;p&gt;A full description of absorbing Markov chains is available on wikipedia, which
is a near verbatim transcription from Kemeny and Snell&amp;rsquo;s book (also available
online). In short, a (Discrete Time, Finite State) Markov chain is a system
that describes the evolution of probability of going from one state to another
in an instantaneous transition. Transitions between states are modelled using a
stochastic matrix (a matrix where the rows must sum to one).&lt;/p&gt;

&lt;p&gt;The wikipedia article on &lt;a href=&#34;http://en.wikipedia.org/wiki/Snakes_and_Ladders&#34;&gt;snakes and
ladders&lt;/a&gt; quotes the solution
as 39.6, for the Milton Bradley version of Chutes and Ladders. That&amp;rsquo;s a useful
baseline for comparison, because the board layout is easy to find online. It&amp;rsquo;s
also worth noting that the page for &lt;a href=&#34;http://en.wikipedia.org/wiki/Absorbing_Markov_chain&#34;&gt;absorbing Markov
chains&lt;/a&gt; quotes the
solution as 39.2.&lt;/p&gt;

&lt;p&gt;Each of the states in the chain represents a location on the board, and we&amp;rsquo;ll
have one extra state (state 0) that represents the initial state off the board.
That means we can conveniently number those state 0 - 100 (inclusive), where 0
is the initial state off the board, and 100 is the terminal state.&lt;/p&gt;

&lt;p&gt;Ignoring (initially) the chutes and ladders, a transition from a state results
in you advancing by the number of squares on a six sided dice.  From any state
$x$, you can reach states $x+1, x+2, &amp;hellip;, x+6$, unless such a transition would
take you off the board (beyond state 100), where the transition is invalid
(which means you stay where you are). The probability of each of these
transitions is &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;, except for the edge case where the move is invalid - in
those cases a small adjustment is needed to keep the player in that states.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def snakes_and_ladders_matrix():
    n = 101
    A = np.zeros((n, n))
    for i in xrange(6):
        A += np.diag(np.ones(n-1-i),i+1)

    # work out the cells that are reachable for every initial cell 
    b = np.sum(A, axis=1)

    # update the transition matrix to have a self-edge for every missing edge 
    A += np.diag(6 - b)

    # normalize
    A /= 6.
    
    return A

A = snakes_and_ladders_matrix()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can verify that the resulting matrix is a valid (right) stochastic matrix
trivially - and it&amp;rsquo;s always a good idea to enforce constraints like this when
working with Markov Chains.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.testing.assert_allclose( 1, np.sum(A, axis=1) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for the game with no snakes or ladders, this is enough to show how many
moves it take to finish the game.  The equation for mean number of steps can be
written in terms of the fundamental matrix $N$ and the identity matrix $I$:&lt;/p&gt;

&lt;p&gt;$$
N = (I-Q)^{-1}
$$&lt;/p&gt;

&lt;p&gt;The equation is then&lt;/p&gt;

&lt;p&gt;$$
t = N \mathbf{1}
$$&lt;/p&gt;

&lt;p&gt;Where $\mathbf{1}$ is the column vector of ones. While it&amp;rsquo;s possible to solve
the equation like this, but only just, it&amp;rsquo;s not an effective way to way to use
a computer to solve the equation.  Solutions to linear equations on a computer
are solved in the form:&lt;/p&gt;

&lt;p&gt;$$
A x = b
$$&lt;/p&gt;

&lt;p&gt;But our unknown is on the wrong side of the equation. Somewhat conveniently,
multiplying through by $I-Q$  gives:&lt;/p&gt;

&lt;p&gt;$$
(I-Q) t = \mathbf{1}
$$&lt;/p&gt;

&lt;p&gt;This means we can solve the equation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Q = A[:-1,:-1]
I = np.identity(Q.shape[0])
o = np.ones((Q.shape[0],1))
result = np.linalg.solve(I-Q, o)
print &#39;mean turns to complete (without snakes and ladders)&#39;, result[0, 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which gives 33.3, which is close enough to give confidence that we&amp;rsquo;re in the
ballpark when we add the snakes and ladders.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ladders = np.array([
    [1, 38],  [4, 14],  [9, 31],  [21,42],
    [28,84],  [36,44],  [51,67],  [71,91],
    [80,100]
]) 

snakes = np.array([
    [98, 78],  [95, 75],  [93, 73],  [87, 24],
    [64, 60],  [62, 19],  [56, 53],  [49, 11],
    [48, 26],  [16, 6],
]) 

def snakes_and_ladders_matrix():
    n = 101
    A = np.zeros((n, n))
    for i in xrange(6):
        A += np.diag(np.ones(n-1-i),i+1)

    # work out the cells that are reachable for every initial cell 
    b = np.sum(A, axis=1)

    # update the transition matrix to have a self-edge for every missing edge 
    A += np.diag(6 - b)

    edges = np.vstack([ladders, snakes])

    for src, dst in edges:
        b = A[:, src].copy()
        A[:, dst] += b
        A[:, src] = 0
    
    A /= 6.
    return A


A = snakes_and_ladders_matrix()
assert_allclose( 1, np.sum(A, axis=1) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And running the code gives the solution&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Q = A[:-1,:-1]
I = np.identity(Q.shape[0])
o = np.ones((Q.shape[0],1))
result = np.linalg.solve(I-Q, o)
print &#39;mean turns to complete&#39;, result[0, 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gives 39.598&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Markov chains and Directed Graphs</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</link>
      <pubDate>Fri, 22 May 2015 09:47:11 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</guid>
      <description>&lt;p&gt;One of the simplest possible probabilistic concepts is that of a Finite Markov
chain.  The basic principle of a Markov chain is that it describes how
something (a state) changes over time.  In effect, if you start in a state,
after some time, a transition occurs, and state updates.  If this sounds
familiar, it&amp;rsquo;s not surprising, Markov chains share many common features with
directed graphs.&lt;/p&gt;

&lt;p&gt;My interest lies more in their applications to statistical physics (which is a
fancy term for describing study of the motion of lots of little bits of stuff).
For my application, Markov chains have been helpful as a tool for developing
initution into more complex systems.&lt;/p&gt;

&lt;p&gt;So what are the similarities between Markov chains and Graphs?&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Markov Chains&lt;/th&gt;
&lt;th&gt;Graph Theory&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Markov Chain&lt;/td&gt;
&lt;td&gt;Directed Graph with edges labelled with transition probability&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;State&lt;/td&gt;
&lt;td&gt;Vertex&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transition&lt;/td&gt;
&lt;td&gt;Edge&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) = 0$&lt;/td&gt;
&lt;td&gt;No edge from $(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) &amp;gt; 0$&lt;/td&gt;
&lt;td&gt;Edge from $(i, j)$, with weight $T(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Accessible $i \rightarrow j$&lt;/td&gt;
&lt;td&gt;Reachable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communicating Classes $(i \leftrightarrow j)$&lt;/td&gt;
&lt;td&gt;Strongly Connected Components&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Permutation of a MC&lt;/td&gt;
&lt;td&gt;Isomorphism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transpose $T&amp;rsquo;$&lt;/td&gt;
&lt;td&gt;Flip edges in graph&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Absorbing $T(i,i) = 1$&lt;/td&gt;
&lt;td&gt;There exists an edge $(s, s)$, and the out degree of $s = 1$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>