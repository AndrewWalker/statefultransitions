<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stateful Transitions</title>
    <link>http://andrewwalker.github.io/statefultransitions/</link>
    <description>Recent content on Stateful Transitions</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 May 2015 09:47:11 +1000</lastBuildDate>
    <atom:link href="http://andrewwalker.github.io/statefultransitions/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Markov chains and Directed Graphs</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</link>
      <pubDate>Fri, 22 May 2015 09:47:11 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</guid>
      <description>&lt;p&gt;One of the simplest possible probabilistic concepts is that of a Finite Markov
chain.  The basic principle of a Markov chain is that it describes how
something (a state) changes over time.  In effect, if you start in a state,
after some time, a transition occurs, and state updates.  If this sounds
familiar, it&amp;rsquo;s not surprising, Markov chains share many common features with
directed graphs.&lt;/p&gt;

&lt;p&gt;My interest lies more in their applications to statistical physics (which is a
fancy term for describing study of the motion of lots of little bits of stuff).
For my application, Markov chains have been helpful as a tool for developing
initution into more complex systems.&lt;/p&gt;

&lt;p&gt;So what are the similarities between Markov chains and Graphs?&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Markov Chains&lt;/th&gt;
&lt;th&gt;Graph Theory&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Markov Chain&lt;/td&gt;
&lt;td&gt;Directed Graph with edges labelled with transition probability&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;State&lt;/td&gt;
&lt;td&gt;Vertex&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transition&lt;/td&gt;
&lt;td&gt;Edge&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) = 0$&lt;/td&gt;
&lt;td&gt;No edge from $(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) &amp;gt; 0$&lt;/td&gt;
&lt;td&gt;Edge from $(i, j)$, with weight $T(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Accessible $i \rightarrow j$&lt;/td&gt;
&lt;td&gt;Reachable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communicating Classes $(i \leftrightarrow j)$&lt;/td&gt;
&lt;td&gt;Strongly Connected Components&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Permutation of a MC&lt;/td&gt;
&lt;td&gt;Isomorphism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transpose $T&amp;rsquo;$&lt;/td&gt;
&lt;td&gt;Flip edges in graph&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Absorbing $T(i,i) = 1$&lt;/td&gt;
&lt;td&gt;There exists an edge $(s, s)$, and the out degree of $s = 1$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Making numpy&#39;s spacing more like MATLAB&#39;s eps</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/matlabeps/</link>
      <pubDate>Tue, 19 May 2015 21:35:28 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/matlabeps/</guid>
      <description>&lt;p&gt;Anyone who has worked with scientists knows the tension between MATLAB and
Python, the oft-repeated closed vs open source debate. For those who straddle
the gap, it&amp;rsquo;s important to know where to go to get help when you&amp;rsquo;re moving
between the two worlds.  From a Python perspective, the most upto date
reference is &lt;a href=&#34;http://wiki.scipy.org/NumPy_for_Matlab_Users&#34;&gt;Numpy for MATLAB
users&lt;/a&gt; on the scipy wiki.&lt;/p&gt;

&lt;p&gt;During the process of porting the &lt;a href=&#34;https://github.com/AndrewWalker/cmtoolkit&#34;&gt;conformal mapping
toolkit&lt;/a&gt;, one of the issues that
came up related to MATLAB&amp;rsquo;s &lt;a href=&#34;mathworks.com/help/matlab/ref/eps.html&#34;&gt;eps&lt;/a&gt;
function. This function determines what the interval to the next floating point
number is - an important prerequisite in doing approximately equal tests on
floating point numbers.&lt;/p&gt;

&lt;p&gt;The guide (correctly) describes that &lt;code&gt;eps&lt;/code&gt; is equivalent to the numpy
&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/ufuncs.html&#34;&gt;ufunc&lt;/a&gt; &lt;code&gt;np.spacing(1)&lt;/code&gt;.
More information about exactly what spacing does is provided by the numpy
&lt;code&gt;info&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

np.info(np.spacing) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The documentation states that the ufunc returns &amp;ldquo;the distance between x and the
nearest adjacent number&amp;rdquo;.  However, MATLAB`s eps seems to differ from spacing
in two important ways.  Firstly, the values it returns are always positive
(it&amp;rsquo;s the &lt;em&gt;absolute&lt;/em&gt;) spacing information. Second, and more importantly, it
also deals with complex values, which is critical for conformal mapping.&lt;/p&gt;

&lt;p&gt;So a slightly revised version of &lt;code&gt;eps&lt;/code&gt; for python might read:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def eps(z):
    &amp;quot;&amp;quot;&amp;quot;Equivalent to MATLAB eps
    &amp;quot;&amp;quot;&amp;quot;
    zre = np.real(z)
    zim = np.imag(z)
    return np.spacing(np.max([zre, zim]))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>welcome</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/welcome/</link>
      <pubDate>Tue, 19 May 2015 20:55:21 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/welcome/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>