<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stateful Transitions</title>
    <link>http://andrewwalker.github.io/statefultransitions/</link>
    <description>Recent content on Stateful Transitions</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jun 2015 21:23:37 +1000</lastBuildDate>
    <atom:link href="http://andrewwalker.github.io/statefultransitions/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Snakes and Ladders</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/snakes-and-ladders/</link>
      <pubDate>Tue, 02 Jun 2015 21:23:37 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/snakes-and-ladders/</guid>
      <description>&lt;p&gt;One of the simplest non-trivial examples of something interesting to do with
Markov chains (that&amp;rsquo;s pretty easy to visualise and understand) is working out
how many moves (on average) it takes to complete a game of snakes and ladders?
This selection of an example is somewhat intentional because it&amp;rsquo;s the same
example as the wikipedia entry for &lt;a href=&#34;http://en.wikipedia.org/wiki/Absorbing_Markov_chain&#34;&gt;absorbing Markov
chains&lt;/a&gt;, and because it&amp;rsquo;s
just hard enough to actually justify solving the problem properly.&lt;/p&gt;

&lt;p&gt;A full description of absorbing Markov chains is available on wikipedia, which
is a near verbatim transcription from Kemeny and Snell&amp;rsquo;s book (also available
online). In short, a (Discrete Time, Finite State) Markov chain is a system
that describes the evolution of probability of going from one state to another
in an instantaneous transition. Transitions between states are modelled using a
stochastic matrix (a matrix where the rows must sum to one).&lt;/p&gt;

&lt;p&gt;The wikipedia article on &lt;a href=&#34;http://en.wikipedia.org/wiki/Snakes_and_Ladders&#34;&gt;snakes and
ladders&lt;/a&gt; quotes the solution
as 39.6, for the Milton Bradley version of Chutes and Ladders. That&amp;rsquo;s a useful
baseline for comparison, because the board layout is easy to find online. It&amp;rsquo;s
also worth noting that the page for &lt;a href=&#34;http://en.wikipedia.org/wiki/Absorbing_Markov_chain&#34;&gt;absorbing Markov
chains&lt;/a&gt; quotes the
solution as 39.2.&lt;/p&gt;

&lt;p&gt;Each of the states in the chain represents a location on the board, and we&amp;rsquo;ll
have one extra state (state 0) that represents the initial state off the board.
That means we can conveniently number those state 0 - 100 (inclusive), where 0
is the initial state off the board, and 100 is the terminal state.&lt;/p&gt;

&lt;p&gt;Ignoring (initially) the chutes and ladders, a transition from a state results
in you advancing by the number of squares on a six sided dice.  From any state
$x$, you can reach states $x+1, x+2, &amp;hellip;, x+6$, unless such a transition would
take you off the board (beyond state 100), where the transition is invalid
(which means you stay where you are). The probability of each of these
transitions is &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;, except for the edge case where the move is invalid - in
those cases a small adjustment is needed to keep the player in that states.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def snakes_and_ladders_matrix():
    n = 101
    A = np.zeros((n, n))
    for i in xrange(6):
        A += np.diag(np.ones(n-1-i),i+1)

    # work out the cells that are reachable for every initial cell 
    b = np.sum(A, axis=1)

    # update the transition matrix to have a self-edge for every missing edge 
    A += np.diag(6 - b)

    # normalize
    A /= 6.
    
    return A

A = snakes_and_ladders_matrix()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can verify that the resulting matrix is a valid (right) stochastic matrix
trivially - and it&amp;rsquo;s always a good idea to enforce constraints like this when
working with Markov Chains.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.testing.assert_allclose( 1, np.sum(A, axis=1) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for the game with no snakes or ladders, this is enough to show how many
moves it take to finish the game.  The equation for mean number of steps can be
written in terms of the fundamental matrix $N$ and the identity matrix $I$:&lt;/p&gt;

&lt;p&gt;$$
N = (I-Q)^{-1}
$$&lt;/p&gt;

&lt;p&gt;The equation is then&lt;/p&gt;

&lt;p&gt;$$
t = N \mathbf{1}
$$&lt;/p&gt;

&lt;p&gt;Where $\mathbf{1}$ is the column vector of ones. While it&amp;rsquo;s possible to solve
the equation like this, but only just, it&amp;rsquo;s not an effective way to use
a computer to solve the equation.  Solutions to linear equations on a computer
are solved in the form:&lt;/p&gt;

&lt;p&gt;$$
A x = b
$$&lt;/p&gt;

&lt;p&gt;But our unknown is on the wrong side of the equation. Somewhat conveniently,
multiplying through by $I-Q$  gives:&lt;/p&gt;

&lt;p&gt;$$
(I-Q) t = \mathbf{1}
$$&lt;/p&gt;

&lt;p&gt;This means we can solve the equation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Q = A[:-1,:-1]
I = np.identity(Q.shape[0])
o = np.ones((Q.shape[0],1))
result = np.linalg.solve(I-Q, o)
print &#39;mean turns to complete (without snakes and ladders)&#39;, result[0, 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which gives 33.3, which is close enough to give confidence that we&amp;rsquo;re in the
ballpark when we add the snakes and ladders.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ladders = np.array([
    [1, 38],  [4, 14],  [9, 31],  [21,42],
    [28,84],  [36,44],  [51,67],  [71,91],
    [80,100]
]) 

snakes = np.array([
    [98, 78],  [95, 75],  [93, 73],  [87, 24],
    [64, 60],  [62, 19],  [56, 53],  [49, 11],
    [48, 26],  [16, 6],
]) 

def snakes_and_ladders_matrix():
    n = 101
    A = np.zeros((n, n))
    for i in xrange(6):
        A += np.diag(np.ones(n-1-i),i+1)

    # work out the cells that are reachable for every initial cell 
    b = np.sum(A, axis=1)

    # update the transition matrix to have a self-edge for every missing edge 
    A += np.diag(6 - b)

    edges = np.vstack([ladders, snakes])

    for src, dst in edges:
        b = A[:, src].copy()
        A[:, dst] += b
        A[:, src] = 0
    
    A /= 6.
    return A


A = snakes_and_ladders_matrix()
assert_allclose( 1, np.sum(A, axis=1) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And running the code gives the solution&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Q = A[:-1,:-1]
I = np.identity(Q.shape[0])
o = np.ones((Q.shape[0],1))
result = np.linalg.solve(I-Q, o)
print &#39;mean turns to complete&#39;, result[0, 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gives 39.598&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stupid Things to do with SCons</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/stupid-things-with-scons1/</link>
      <pubDate>Wed, 27 May 2015 20:21:27 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/stupid-things-with-scons1/</guid>
      <description>&lt;p&gt;&lt;em&gt;TL;DR&lt;/em&gt; Don&amp;rsquo;t use the Python callstack to find variables - it can lead to subtle problems for users of your code.&lt;/p&gt;

&lt;p&gt;This post came about as part of an investigation into extending &lt;a href=&#34;http://www.scons.org/&#34;&gt;SCons&lt;/a&gt; functionality without having to alter the source code. The primary objective was to validate that the absolute path of an SConscript file exists, or provide (improved) feedback if it doesn&amp;rsquo;t. This is important in situations where you&amp;rsquo;re using variant build directories (debug and release) and your builds are spread over many directories.  This is one of the things SCons is particularly poor at reporting diagnostics for.&lt;/p&gt;

&lt;p&gt;If this was just Python, without the magic of SCons happening, this really would be trivial, in fact it&amp;rsquo;s one of those things that Python excels at.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
path = &#39;path/to/your/SConscript&#39;
path = os.path.abspath(os.path.normpath(path))
if not os.path.exists(path):
    raise Exception(&#39;SConcript does not exist at %s&#39; % path)
SConscript(path, ...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Given enough SConscript files, this pattern is annoying and worthy of refactoring. One way to do that would be to pull that code out, and put it into an external module. Given that we&amp;rsquo;ll always want to do this with our calls to SConscript, it&amp;rsquo;s probably easier to adjust the SConscript method, rather than adding a second function. Altering the behavior of Python functions and methods at runtime by pre- or post- fixing code is most easily achieved by using &lt;a href=&#34;https://wiki.python.org/moin/PythonDecorators&#34;&gt;decorators&lt;/a&gt;, which is really just a fancy name for a function that wraps another function.&lt;/p&gt;

&lt;p&gt;A modern decorator would look something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# scommon.py
import os
import wrapt

@wrapt.decorator
def sconcript_validator(wrapped, instance, args, kwargs):
    path = args[0]
    path = os.path.abspath(os.path.normpath(path))
    if not os.path.exists(path):
        raise Exception(&#39;SConcript does not exist at %s&#39; % path)
    return wrapped(*args, **kwargs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that I&amp;rsquo;ve chosen to make use of the &lt;a href=&#34;https://github.com/GrahamDumpleton/wrapt&#34;&gt;wrapt&lt;/a&gt; which deals with all the ugly corner cases of decorators for me.&lt;/p&gt;

&lt;p&gt;This means that I can rewrite my SConstruct as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# SConstruct
import scommon 
menv = Environment()
menv.SConscript = scommon.sconcript_validator(menv.SConscript)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And at that point I should be able to run SCons as per normal, with a nicely updated SConscript function, and everything should be rainbows and unicorns.&lt;/p&gt;

&lt;p&gt;Except it isn&amp;rsquo;t. Instead SCons fails with the traceback&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ scons
scons: Reading SConscript files ...

scons: *** Export of non-existent variable &#39;&#39;menv&#39;&#39;
File &amp;quot;/Users/username/tmp/scommon.py&amp;quot;, line 10, in sconcript_validator
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This occurs because SCons does much of it&amp;rsquo;s heavy lifting by making use of the Python callstack, finding targets via introspection of the call frames. Unfortunately, the way it does this is somewhat fragile, expecting calling code to be a certain number of stack frames above (the internals of) SConscript.&lt;/p&gt;

&lt;p&gt;From SCons.Script.SConcript:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This is the magic line that actually reads up
# and executes the stuff in the SConscript file
# ...
call_stack[-1].globals.update({stack_bottom:1})
old_file = call_stack[-1].globals.get(&#39;__file__&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And eventually:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exec _file_ in call_stack[-1].globals
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The consequence of this is that, to the best of my knowledge, there is no easy way to decorate the SConscript method.&lt;/p&gt;

&lt;p&gt;All&amp;rsquo;s not lost, the dynamic nature of Python means we can reach directly into the SConcript module, introspect data about the code, including getting the original source code using &lt;a href=&#34;https://docs.python.org/2/library/inspect.html&#34;&gt;inspect&lt;/a&gt;, rewrite the lines of that function, &lt;a href=&#34;https://docs.python.org/2/reference/simple_stmts.html#exec&#34;&gt;exec&lt;/a&gt; that string in the context of the original functions scope, before replacing the function back on the class with &lt;a href=&#34;https://docs.python.org/2/library/functions.html#setattr&#34;&gt;setattr&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://gist.github.com/AndrewWalker/d9d74f5f46651c6607b4&#34;&gt;final result&lt;/a&gt;
looks like the ugliest Python I&amp;rsquo;ve written for a long while. Somehow I don&amp;rsquo;t
think this one&amp;rsquo;s going to make it past code-review.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Markov chains and Directed Graphs</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</link>
      <pubDate>Fri, 22 May 2015 09:47:11 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/markov-chains/</guid>
      <description>&lt;p&gt;One of the simplest possible probabilistic concepts is that of a Finite Markov
chain.  The basic principle of a Markov chain is that it describes how
something (a state) changes over time.  In effect, if you start in a state,
after some time, a transition occurs, and state updates.  If this sounds
familiar, it&amp;rsquo;s not surprising, Markov chains share many common features with
directed graphs.&lt;/p&gt;

&lt;p&gt;My interest lies more in their applications to statistical physics (which is a
fancy term for describing study of the motion of lots of little bits of stuff).
For my application, Markov chains have been helpful as a tool for developing
initution into more complex systems.&lt;/p&gt;

&lt;p&gt;So what are the similarities between Markov chains and Graphs?&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Markov Chains&lt;/th&gt;
&lt;th&gt;Graph Theory&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Markov Chain&lt;/td&gt;
&lt;td&gt;Directed Graph with edges labelled with transition probability&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;State&lt;/td&gt;
&lt;td&gt;Vertex&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transition&lt;/td&gt;
&lt;td&gt;Edge&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) = 0$&lt;/td&gt;
&lt;td&gt;No edge from $(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T(i, j) &amp;gt; 0$&lt;/td&gt;
&lt;td&gt;Edge from $(i, j)$, with weight $T(i, j)$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Accessible $i \rightarrow j$&lt;/td&gt;
&lt;td&gt;Reachable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communicating Classes $(i \leftrightarrow j)$&lt;/td&gt;
&lt;td&gt;Strongly Connected Components&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Permutation of a MC&lt;/td&gt;
&lt;td&gt;Isomorphism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transpose $T&amp;rsquo;$&lt;/td&gt;
&lt;td&gt;Flip edges in graph&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Absorbing $T(i,i) = 1$&lt;/td&gt;
&lt;td&gt;There exists an edge $(s, s)$, and the out degree of $s = 1$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Making numpy&#39;s spacing more like MATLAB&#39;s eps</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/matlabeps/</link>
      <pubDate>Tue, 19 May 2015 21:35:28 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/matlabeps/</guid>
      <description>&lt;p&gt;Anyone who has worked with scientists knows the tension between MATLAB and
Python, the oft-repeated closed vs open source debate. For those who straddle
the gap, it&amp;rsquo;s important to know where to go to get help when you&amp;rsquo;re moving
between the two worlds.  From a Python perspective, the most upto date
reference is &lt;a href=&#34;http://wiki.scipy.org/NumPy_for_Matlab_Users&#34;&gt;Numpy for MATLAB
users&lt;/a&gt; on the scipy wiki.&lt;/p&gt;

&lt;p&gt;During the process of porting the &lt;a href=&#34;https://github.com/AndrewWalker/cmtoolkit&#34;&gt;conformal mapping
toolkit&lt;/a&gt;, one of the issues that
came up related to MATLAB&amp;rsquo;s &lt;a href=&#34;mathworks.com/help/matlab/ref/eps.html&#34;&gt;eps&lt;/a&gt;
function. This function determines what the interval to the next floating point
number is - an important prerequisite in doing approximately equal tests on
floating point numbers.&lt;/p&gt;

&lt;p&gt;The guide (correctly) describes that &lt;code&gt;eps&lt;/code&gt; is equivalent to the numpy
&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/ufuncs.html&#34;&gt;ufunc&lt;/a&gt; &lt;code&gt;np.spacing(1)&lt;/code&gt;.
More information about exactly what spacing does is provided by the numpy
&lt;code&gt;info&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

np.info(np.spacing) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The documentation states that the ufunc returns &amp;ldquo;the distance between x and the
nearest adjacent number&amp;rdquo;.  However, MATLAB`s eps seems to differ from spacing
in two important ways.  Firstly, the values it returns are always positive
(it&amp;rsquo;s the &lt;em&gt;absolute&lt;/em&gt;) spacing information. Second, and more importantly, it
also deals with complex values, which is critical for conformal mapping.&lt;/p&gt;

&lt;p&gt;So a slightly revised version of &lt;code&gt;eps&lt;/code&gt; for python might read:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def eps(z):
    &amp;quot;&amp;quot;&amp;quot;Equivalent to MATLAB eps
    &amp;quot;&amp;quot;&amp;quot;
    zre = np.real(z)
    zim = np.imag(z)
    return np.spacing(np.max([zre, zim]))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>welcome</title>
      <link>http://andrewwalker.github.io/statefultransitions/post/welcome/</link>
      <pubDate>Tue, 19 May 2015 20:55:21 +1000</pubDate>
      
      <guid>http://andrewwalker.github.io/statefultransitions/post/welcome/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>